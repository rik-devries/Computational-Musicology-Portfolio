---
title: "Portfolio"
author: "Rik de Vries"
date: "2/19/2022"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    vertical_layout: fill
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(spotifyr)
library(tidyverse)
library(plotly)
library(flexdashboard)
library(compmus)
all_lp_tracks <- get_playlist_audio_features("", "1y9QYGfYFzSO7EF53wwLiB")
```

### Linkin Park's albums over time as the corpus selection
<center>
<h1>Linkin Park: Old vs New</h1>
<img src="https://i.scdn.co/image/ab67616d0000b273e2f039481babe23658fc719a" alt="Hybrid Theory" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b27391e2fd0e284ca923b8743b6a" alt="Reanimation" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273ce4b724f4332773136067d8c" alt="Meteora" width="20%"/>

<img src="https://i.scdn.co/image/ab67616d0000b27346e207de66ba06422897f769" alt="Minutes to Midnight" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273302a793ccd682e6549c91f10" alt="A Thousand Suns" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273987fb4c5ec8790e9f637a4a4" alt="LIVING THINGS" width="20%"/>

<img src="https://i.scdn.co/image/ab67616d0000b2737cb20e0a29701a667dac3ede" alt="Recharged" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b2735721adac031512b903f10d03" alt="The Hunting Party" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273145e1cf12538f5666511237d" alt="One More Light" width="20%"/>
</center>

***
<iframe src="https://open.spotify.com/embed/playlist/7MATpbz5p1afYISxOgY7ek?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

In this report, we will take a closer look at different albums from Linkin Park on Spotify. These albums are interesting to look at as the band has made a lot of changes over the years. Their early albums were very raw, as they produced a lot of music that defined the nu metal genre. The style in which they produced music has changed a lot over time. Their last album, *One More Light* has been categorized into the Pop and Indie genres. In this deeper dive we will take a lot at what defined earlier albums, and what exactly changed over time.

Comparing all these songs should give a decent picture of how the band and its members changed over time. There are some limitations to this corpus, as the band used to have a different lead singer, Mark Wakefield, but they never released an official album back then. Next to that, the group has released many "Underground" albums, which are not on Spotify. These would have been very interesting to include in the corpus as well, to see if there are visible differences between the officially released albums and the albums that did not receive the same type of polishing.

### Album popularity dips but picks up to original heights
```{r pop_plot2, fig.height = 6, fig.width = 10, fig.align = "center", echo=FALSE}
# Filter out songs that have been duplicated
# (republished under the 20th anniversary album), along with inbetween-tracks
# that are shorter than a minute as these are not songs.
unq_lp_tracks = distinct(all_lp_tracks, track.name, .keep_all = TRUE) %>% 
  filter(track.duration_ms > 60000, track.album.album_type == "album")

unq_lp_tracks$year_album_published = 
  as.Date(format(as.Date(unq_lp_tracks$track.album.release_date, 
                         format="%Y-%m-%d"),"%Y"), "%Y")

main_albums <- c("Hybrid Theory (Bonus Edition)","Meteora (Bonus Edition)", "Minutes to Midnight",  "A Thousand Suns", "LIVING THINGS","The Hunting Party", "One More Light")
main_album_tracks <- unq_lp_tracks %>% filter(track.album.name %in% main_albums)
main_albums_plot <- ggplot(main_album_tracks, aes(x=year_album_published, y=track.popularity)) +
  labs(title="Linkin Park track popularity over time", x="Year", y="Popularity", color = "Album") +
  lims(y=c(0, 100)) +
  geom_point(aes(color=track.album.name, text=sprintf("Track: %s<br>Album: %s<br>Popularity: %s", track.name, track.album.name, track.popularity))) + 
  geom_smooth(aes(text=""))
#"Year: %s<br>Popularity: %s", year_album_published, track.popularity
w <- ggplotly(main_albums_plot, tooltip=c("text"))

# Disable hover for geom_smooth (trace 9) (Lower trace indices are for albums)
w %>%
  style(hoverinfo = "none", traces = 9)
```

***
The following plot shows the popularity of tracks from the main albums of the band Linkin Park. 
Data points on the chart can be hovered to get specific information (track name, the album it belongs to and its popularity).

To give a clear image of the band's popularity, the plot only relies on tracks from main albums. It therefore excludes remix albums and albums made after Chester Bennington's death.
The plot shows a trend that starts off downward sloping, with an all-time low in 2010. After this lowpoint though, it climbs back up to early 2000-levels. 

It does therefore seem that in either style, the band manages to attract large amounts of listeners. It looks like it did take a while for the fans to get used to the new style though, with some in-between albums not performing as well.

### Tracks get more well-defined pitch classes over time 
```{r echo=FALSE}
one_more_light <-
  get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
in_the_end <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```

```{r fig.height = 6, fig.width = 10, fig.align = "center", echo=FALSE}
plot_oml <- one_more_light %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value,
      text = sprintf("Time: %.0f seconds<br>Pitch class: %s<br>Magnitude: %s", start + duration / 2, pitch_class, value)
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
plot_ite <- in_the_end %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value,
      text = sprintf("Time: %.0f seconds<br>Pitch class: %s<br>Magnitude: %s", start + duration / 2, pitch_class, value)
      )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

plt1 <- ggplotly(plot_ite, tooltip="text")
plt2 <- ggplotly(plot_oml, tooltip="text")
w <- subplot(plt1, plt2)
w %>%
  layout(title = 'In the End vs One More Light')

#w %>%
#  
#  #style(hoverinfo = "none") %>%
#  layout(annotations = list(
# list(x = 0.17 , y = 1.065, text = "In the End", showarrow = F, xref='paper', yref='paper'),
#  list(x = 0.87 , y = 1.065, text = "One More Light", showarrow = F, xref='paper', yref='paper'))
#)

```
***
This plot shows the chromagrams from two of Linkin Park's most popular songs, one from their first album and one from their last album. The song on the left is *In the End*, and the song on the right is *One More Light*. 

The first song changes a lot over the course of its duration. It has many instruments: piano, guitar, drums, electric instruments and there seems to be some electric crackling noises added too. On top of all of that, it has both Chester Bennington singing loudly, mixed with Mike Shinoda rapping. This leads to a very mixed chromagram where, even though the main notes are clearly visible, there is a lot of spread to other notes. 

One More Light takes a very different approach. It has very well-defined chroma's with barely any spread to other pitch classes. The song is much more emotional, and less rock-like than *In the End*. It does not nearly contain as many instruments, or as much diversity. This displays a large difference between the two songs and their respective albums.

The chromagram show some sections of the song very well. *In the End* clearly shows an intro up until 20 seconds, after which the actual song starts. It is very difficult to spot any differences in this section. At around 3 minutes, the outro starts. These three sections are clearly distinguished.
For *One More Light*, the visible parts of the song are more difficult to distinguish. Most of the song is sung in G#, with some deviations to F and C# pitches. The outro clearly starts at 4 minutes.

### The structure of early songs follows clear patterns
```{r echo=FALSE}
# In the end 60a0Rd6pjrkxjPbaKzXjfq
# One more light 3xXBsjrbG1xQIm1xv1cKOt
ite_plot <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
mix_plot_1 <-bind_rows(
  ite_plot %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  ite_plot %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

oml_plot <-
  get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
mix_plot_2 <- bind_rows(
  oml_plot %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  oml_plot %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

ggplotly(mix_plot_1)

```

***
On this and the next tab, we will compare the self-similarity matrices of *In the End* and *One More Light*. These matrices tell us an important difference between old and new songs.

As could be seen in the chromagrams on the previous tab, *In the End* starts off with a D#, F, F# and A#. These are almost nowhere to be seen in the rest of the song, so it is only similar to itself. The song then goes on to play some different notes that persist for almost the whole song, with C# being the most pronounced. 
The timbre self-similarity matrix tells an equally interesting story. The instrumentals in the beginning are definitely unique. That is because they are mixed in with electric/static noises. If they would not have been, they would have been similar to the instrumentals in the outro. The matrix shows the layout of the song very well. At around 20 seconds, Mike Shinoda starts rapping. This is something he also does at around 80 seconds, which is why the self-similarity matrix shows a connection between these two time points. Chester Bennington sings the chorus three times, with the third time being led by a bridge. The three areas are very visible in the matrix. Half of the bridge is sung in a calm way that is unique to any other moment in the song. The other half of the bridge sounds a lot like the chorus, which is why the square that starts at 150 seconds is so much larger than the other two.

### Older and newer songs have similar structures, but very different execution
```{r echo=FALSE}
ggplotly(mix_plot_2)
```

***
When comparing *In the End* to *One More Light*, we see the songs are sung in a very different way. For *One more Light*, a lot of the song is sung in the G# key, as can be seen earlier shown chromagram. This is mixed in with a bit of the F key and some of the C# chroma.
The repetition of these three chromas (mainly the G# key) makes for the pattern we see in the self-similarity matrix. The dark square we see at 70 seconds is the first repetition of the chorus. The chromagram does not clearly show when the chorus repeats though, for this we need to look at the timbre matrix. This clearly shows the chorus is song again at around 150 seconds and then a final time at 210 seconds.
At around 3 minutes in we see a dark blue square that is not similar to anything in the song, except a bit to the intro. This is a relaxed instrumental bridge. It is similar to the intro because the this also only contained instrumental music. The two yellow lines visible at 125 and 135 seconds are long pauses between two sentences, where there is almost no sound at all. These are not similar to any other points in the song.

So while both *In the End* and *One More Light* clearly show verses and choruses being similar, the chromagram shows that *One More Light* alternates a lot more between chromas than *In the End*, which looks like a much more linear song. The timbre matrices show that both songs have unique points next to repetition. In *One More Light* these are slow instrumental pieces, or moments of complete silence. In *In the End* this was a bridge where there was a moment of less intense singing, which then transitioned into the last repetition of the chorus.

### Songs in newer albums show clear patterns for the used chords
```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
```

```{r, echo = FALSE}
#3xXBsjrbG1xQIm1xv1cKOt OML
#60a0Rd6pjrkxjPbaKzXjfq ITE
chordogram <- get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) %>% 
  compmus_match_pitch_template(chord_templates, "euclidean", "manhattan") %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

ggplotly(chordogram)
```

***
This plot shows the chordogram of *One More Light*. One of the most obviously visible things is the repeating pattern that starts in Ab major, then lowers to Ab7 en drops down to Db major. This is indeed the audible pattern in the song. It starts all the way at the beginning already as the melody then starts, with heavy reverb. Such a downward loop makes for an emotionally sounding song that feels kind of sad and like it's in a negative, downward spiral. This makes a lot of sense considering Chester Benningtons state of life when he sung the song. A few months after the song had been released, Chester decided to end it all.

### Older songs incorporate a lot of novelty to keep listeners engaged
```{r, echo = FALSE}
ite_data <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  select(segments) %>%
  unnest(segments)
```
```{r, echo = FALSE}
ite_loudness <- ite_data %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  geom_line() +
#  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty", title = "Loudness-based novelty function")
ite_pitches <- ite_data %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  arrange(start) %>%
  mutate(pitches = map2(pitches, lag(pitches), `-`)) %>%
  slice(-1) %>% 
  compmus_gather_chroma() %>% 
  group_by(start, duration) %>% 
  summarise(novelty = sum(log1p(pmax(value, 0)))) %>% 
  ggplot(aes(x = start + duration / 2, y = novelty)) +
  geom_line() +
#  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty", title = "Pitch-based novelty function")
ite_timbre <- ite_data %>%
  arrange(start) %>%
  mutate(timbre = map2(timbre, lag(timbre), `-`)) %>%
  slice(-1) %>%
  compmus_gather_timbre() %>%
  group_by(start, duration) %>% 
  summarise(novelty = sum(log1p(pmax(value, 0)))) %>% 
  ggplot(aes(x = start + duration / 2, y = novelty)) +
  geom_line() +
#  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")

subplot(ite_loudness, ite_pitches, ite_timbre) %>%
  layout(title = 'Loudness, pitch and timbre-based novelty graphs')

```
***
In the figure we can see three different types of novelty graphs for the song *In the End*. We have the loudness, pitch and timbre based novelty graphs. The loudness based graph has a huge peak at the start which makes sense, as we then go from no music at all to the start of the song. We see many logical spikes, such as at 18 seconds when the song moves from the intro to the first verse or the spike when we go from the chorus to another verse at 130 seconds. 
This verse following the chorus starts with a line split in terms of tones. '*I've put my trust*', '*in you..*' where the second part is sung in a much lower voice. This is why we see such a huge spike in the pitch-based novelty graph at this same time stamp (134 seconds).
The largest spike we see for the timbre-based novelty graph is at 21 seconds. This is completely logical, as the intro was played on a piano with electric static noises in it, and at 21 seconds the drums and flute-like instrument kick in. 

### Older songs have very well-defined BPM's
```{r echo=FALSE}
ite_data <- get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq")

ite_tempogram <- ite_data %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
ggplotly(ite_tempogram)
```
***

For the track *In the End* we can see the BPM of the whole song pretty clearly. Most of the line stays on 105 BPM, with some small exceptions. We deviate from the line at 70 seconds, 130 seconds and with the outro. Looking at the loudness novelty graph, we see that the novelty is at a lowpoint. This makes it so that the algorithm cannot find enough new points to figure out what the BPM really is. With 130 seconds, it is the other way around. The loudness novelty graph is peaking heavily. This is because the music goes from a heavy chorus into a more relaxed break. It does this using a small window with barely any music at all. This makes it so that the algorithm is getting confused as to which parts of the song it should look for to determine the BPM. 
Finally, in the outro, the music slows down which is very visible in the loudness and timbre based novelty graphs. Now the algorithm lacks data points to determine the BPM again.
