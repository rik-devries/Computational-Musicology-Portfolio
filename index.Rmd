---
title: "Linkin Park Album Analysis"
author: "Rik de Vries"
date: "February/March 2022"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    vertical_layout: fill
---
<style>
.sbframe-commentary {
  width: 400px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(spotifyr)
library(tidyverse)
library(plotly)
library(flexdashboard)
library(compmus)
library(ape)
library(tidymodels)
library(ggdendro)
library(heatmaply)

all_lp_tracks <- get_playlist_audio_features("", "1y9QYGfYFzSO7EF53wwLiB")
```

### Linkin Park's albums over time as the corpus selection
<center>
<h1>Linkin Park: Old vs New</h1>
<img src="https://i.scdn.co/image/ab67616d0000b273e2f039481babe23658fc719a" alt="Hybrid Theory" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b27391e2fd0e284ca923b8743b6a" alt="Reanimation" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273ce4b724f4332773136067d8c" alt="Meteora" width="20%"/>

<img src="https://i.scdn.co/image/ab67616d0000b27346e207de66ba06422897f769" alt="Minutes to Midnight" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273302a793ccd682e6549c91f10" alt="A Thousand Suns" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273987fb4c5ec8790e9f637a4a4" alt="LIVING THINGS" width="20%"/>

<img src="https://i.scdn.co/image/ab67616d0000b2737cb20e0a29701a667dac3ede" alt="Recharged" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b2735721adac031512b903f10d03" alt="The Hunting Party" width="20%"/>
<img src="https://i.scdn.co/image/ab67616d0000b273145e1cf12538f5666511237d" alt="One More Light" width="20%"/>
</center>

***
<iframe src="https://open.spotify.com/embed/playlist/7MATpbz5p1afYISxOgY7ek?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

In this report, we will take a closer look at different albums from Linkin Park on Spotify. These albums are interesting to look at as the band has made a lot of changes over the years. Their early albums were very raw, as they produced a lot of music that defined the nu metal genre. The style in which they produced music has changed a lot over time. Their last album, *One More Light* has been categorized into the Pop and Indie genres. In this deeper dive we will take a lot at what defined earlier albums, and what exactly changed over time.

Comparing all these songs should give a decent picture of how the band and its members changed over time. There are some limitations to this corpus, as the band used to have a different lead singer, Mark Wakefield, but they never released an official album back then. Next to that, the group has released many "Underground" albums, which are not on Spotify. These would have been very interesting to include in the corpus as well, to see if there are visible differences between the officially released albums and the albums that did not receive the same type of polishing.

### Album popularity dips but picks up to original heights
```{r pop_plot2, fig.height = 6, fig.width = 10, fig.align = "center", echo=FALSE}
# Filter out songs that have been duplicated
# (republished under the 20th anniversary album), along with inbetween-tracks
# that are shorter than a minute as these are not songs.
unq_lp_tracks = distinct(all_lp_tracks, track.name, .keep_all = TRUE) %>% 
  filter(track.duration_ms > 60000, track.album.album_type == "album")

unq_lp_tracks$year_album_published = 
  as.Date(format(as.Date(unq_lp_tracks$track.album.release_date, 
                         format="%Y-%m-%d"),"%Y"), "%Y")

main_albums <- c("Hybrid Theory (Bonus Edition)","Meteora (Bonus Edition)", "Minutes to Midnight",  "A Thousand Suns", "LIVING THINGS","The Hunting Party", "One More Light")
main_album_tracks <- unq_lp_tracks %>% filter(track.album.name %in% main_albums)
main_albums_plot <- ggplot(main_album_tracks, aes(x=year_album_published, y=track.popularity)) +
  labs(title="Linkin Park track popularity over time", x="Year", y="Popularity", color = "Album") +
  lims(y=c(0, 100)) +
  geom_point(aes(color=track.album.name, text=sprintf("Track: %s<br>Album: %s<br>Popularity: %s", track.name, track.album.name, track.popularity))) + 
  geom_smooth(aes(text=""))
#"Year: %s<br>Popularity: %s", year_album_published, track.popularity
w <- ggplotly(main_albums_plot, tooltip=c("text"))

# Disable hover for geom_smooth (trace 9) (Lower trace indices are for albums)
w %>%
  style(hoverinfo = "none", traces = 9)
```

***
The following plot shows the popularity of tracks from the main albums of the band Linkin Park. 
Data points on the chart can be hovered to get specific information (track name, the album it belongs to and its popularity).

To give a clear image of the band's popularity, the plot only relies on tracks from main albums. It therefore excludes remix albums and albums made after Chester Bennington's death.
The plot shows a trend that starts off downward sloping, with an all-time low in 2010. After this lowpoint though, it climbs back up to early 2000-levels. 

It does therefore seem that in either style, the band manages to attract large amounts of listeners. It looks like it did take a while for the fans to get used to the new style though, with some in-between albums not performing as well.

### Tracks get more well-defined pitch classes over time 
```{r echo=FALSE}
one_more_light <-
  get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
in_the_end <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```

```{r fig.height = 6, fig.width = 10, fig.align = "center", echo=FALSE}
plot_oml <- one_more_light %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value,
      text = sprintf("Time: %.0f seconds<br>Pitch class: %s<br>Magnitude: %s", start + duration / 2, pitch_class, value)
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
plot_ite <- in_the_end %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value,
      text = sprintf("Time: %.0f seconds<br>Pitch class: %s<br>Magnitude: %s", start + duration / 2, pitch_class, value)
      )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

plt1 <- ggplotly(plot_ite, tooltip="text")
plt2 <- ggplotly(plot_oml, tooltip="text")
w <- subplot(plt1, plt2)
w %>%
  layout(title = 'In the End vs One More Light')

#w %>%
#  
#  #style(hoverinfo = "none") %>%
#  layout(annotations = list(
# list(x = 0.17 , y = 1.065, text = "In the End", showarrow = F, xref='paper', yref='paper'),
#  list(x = 0.87 , y = 1.065, text = "One More Light", showarrow = F, xref='paper', yref='paper'))
#)

```
***
This plot shows the chromagrams from two of Linkin Park's most popular songs, one from their first album and one from their last album. The song on the left is *In the End*, and the song on the right is *One More Light*. 

The first song changes a lot over the course of its duration. It has many instruments: piano, guitar, drums, electric instruments and there seems to be some electric crackling noises added too. On top of all of that, it has both Chester Bennington singing loudly, mixed with Mike Shinoda rapping. This leads to a very mixed chromagram where, even though the main notes are clearly visible, there is a lot of spread to other notes. 

One More Light takes a very different approach. It has very well-defined chroma's with barely any spread to other pitch classes. The song is much more emotional, and less rock-like than *In the End*. It does not nearly contain as many instruments, or as much diversity. This displays a large difference between the two songs and their respective albums.

The chromagram show some sections of the song very well. *In the End* clearly shows an intro up until 20 seconds, after which the actual song starts. It is very difficult to spot any differences in this section. At around 3 minutes, the outro starts. These three sections are clearly distinguished.
For *One More Light*, the visible parts of the song are more difficult to distinguish. Most of the song is sung in G#, with some deviations to F and C# pitches. The outro clearly starts at 4 minutes.

### The structure of early songs follows clear patterns
```{r echo=FALSE}
# In the end 60a0Rd6pjrkxjPbaKzXjfq
# One more light 3xXBsjrbG1xQIm1xv1cKOt
ite_plot <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
mix_plot_1 <-bind_rows(
  ite_plot %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  ite_plot %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d, 
      text=sprintf("X-time: %.0f seconds<br>Y-time: %.0f seconds<br>Delta: %.4f", xstart + xduration / 2, ystart + yduration / 2, d)
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

oml_plot <-
  get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
mix_plot_2 <- bind_rows(
  oml_plot %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  oml_plot %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d, 
      text=sprintf("X-time: %.0f seconds<br>Y-time: %.0f seconds<br>Delta: %.4f", xstart + xduration / 2, ystart + yduration / 2, d)
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

ggplotly(mix_plot_1, tooltip=c("text"))

```

***
On this and the next tab, we will compare the self-similarity matrices of *In the End* and *One More Light*. These matrices tell us an important difference between old and new songs. This tab starts off with the self-similarity matrices for *In the End*.

As could be seen in the chromagrams on the previous tab, *In the End* starts off with a D#, F, F# and A#. These are almost nowhere to be seen in the rest of the song, so it is only similar to itself. The song then goes on to play some different notes that persist for almost the whole song, with C# being the most pronounced. 
The timbre self-similarity matrix tells an equally interesting story. The instrumentals in the beginning are definitely unique. That is because they are mixed in with electric/static noises. If they would not have been, they would have been similar to the instrumentals in the outro. The matrix shows the layout of the song very well. At around 20 seconds, Mike Shinoda starts rapping. This is something he also does at around 80 seconds, which is why the self-similarity matrix shows a connection between these two time points. Chester Bennington sings the chorus three times, with the third time being led by a bridge. The three areas are very visible in the matrix. Half of the bridge is sung in a calm way that is unique to any other moment in the song. The other half of the bridge sounds a lot like the chorus, which is why the square that starts at 150 seconds is so much larger than the other two.

### Older and newer songs have similar structures, but very different execution
```{r echo=FALSE}
ggplotly(mix_plot_2, tooltip=c("text"))
```

***
When comparing *In the End* to *One More Light*, we see the songs are sung in a very different way. For *One more Light*, a lot of the song is sung in the G# key, as can be seen earlier shown chromagram. This is mixed in with a bit of the F key and some of the C# chroma.
The repetition of these three chromas (mainly the G# key) makes for the pattern we see in the self-similarity matrix. The dark square we see at 70 seconds is the first repetition of the chorus. The chromagram does not clearly show when the chorus repeats though, for this we need to look at the timbre matrix. This clearly shows the chorus is song again at around 150 seconds and then a final time at 210 seconds.
At around 3 minutes in we see a dark blue square that is not similar to anything in the song, except a bit to the intro. This is a relaxed instrumental bridge. It is similar to the intro because the this also only contained instrumental music. The two yellow lines visible at 125 and 135 seconds are long pauses between two sentences, where there is almost no sound at all. These are not similar to any other points in the song.

So while both *In the End* and *One More Light* clearly show verses and choruses being similar, the chromagram shows that *One More Light* alternates a lot more between chromas than *In the End*, which looks like a much more linear song. The timbre matrices show that both songs have unique points next to repetition. In *One More Light* these are slow instrumental pieces, or moments of complete silence. In *In the End* this was a bridge where there was a moment of less intense singing, which then transitioned into the last repetition of the chorus.

### Songs in newer albums show clear patterns for the used chords
```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
```

```{r, echo = FALSE}
#3xXBsjrbG1xQIm1xv1cKOt OML
#60a0Rd6pjrkxjPbaKzXjfq ITE
chordogram <- get_tidy_audio_analysis("3xXBsjrbG1xQIm1xv1cKOt") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) %>% 
  compmus_match_pitch_template(chord_templates, "euclidean", "manhattan") %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d, text=sprintf("Time: %.0f seconds<br>Chord: %s<br>Delta: %.4f", start + duration / 2, name, d))
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title="Chordogram: One More Light")

ggplotly(chordogram, tooltip="text")
```

***
This plot shows the chordogram of *One More Light*. One of the most obviously visible things is the repeating pattern that starts in Ab major, then lowers to Ab7 en drops down to Db major. This is indeed the audible pattern in the song. It starts all the way at the beginning already as the melody then starts, with heavy reverb. Such a downward loop makes for an emotionally sounding song that feels kind of sad and like it's in a negative, downward spiral. This makes a lot of sense considering Chester Benningtons state of life when he sung the song. A few months after the song had been released, Chester decided to end it all.

### Older songs incorporate a lot of novelty to keep listeners engaged
```{r, echo = FALSE}
ite_data <-
  get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq") %>%
  select(segments) %>%
  unnest(segments)
```
```{r, echo = FALSE}
ite_loudness <- ite_data %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness), text=sprintf("Time: %.0f seconds<br>Novelty: %.4f", loudness_max_time / 2, 0.1))) +
  geom_line() +
#  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")

ggly <- ggplotly(ite_loudness)

text_x <- number(
  ggly$x$data[[1]]$x,
  prefix = "Time: ",
  suffix = " seconds",
  accuracy = 1
)

text_y <- number(
  ggly$x$data[[1]]$y,
  accuracy = 0.0001,
  prefix = "Novelty: ",
)

ggplotly(ite_loudness, tooltip="text") %>%
  style(text = paste0(text_x, "<br>", text_y), traces = 1) %>%
  layout(title = 'Loudness-based novelty graph: In the End')

```
***
In the figure we can see loudness-based novelty graph for the song *In the End*. The graph has a huge peak at the start which makes sense, as we then go from no music at all to the start of the song. We see many logical spikes, such as at 18 seconds when the song moves from the intro to the first verse or the spike at 75 seconds when we enter the second verse. The chorus seems to be characterized by low loudness novelty: one starts at 55 seconds, the next at 100 seconds and the final time at 165 seconds. The spike at 130 seconds is when we enter the second verse from the chorus and at 190 seconds we enter the outro, played by a piano. 

### Older songs have very well-defined BPM's
```{r echo=FALSE}
ite_data <- get_tidy_audio_analysis("60a0Rd6pjrkxjPbaKzXjfq")

ite_tempogram <- ite_data %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power, text=sprintf("Time: %.0f seconds<br>BPM: %s<br>Power: %.4f", time, bpm, power))) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title="Tempogram: In the End") +
  theme_classic()
ggplotly(ite_tempogram, tooltip="text")
```
***

For the track *In the End* we can see the BPM of the whole song pretty clearly. Most of the line stays on 105 BPM, with some small exceptions. We deviate from the line at 70 seconds, 130 seconds and with the outro. Looking at the loudness novelty graph, we see that the novelty is at a lowpoint. This makes it so that the algorithm cannot find enough new points to figure out what the BPM really is. With 130 seconds, it is the other way around. The loudness novelty graph is peaking heavily. This is because the music goes from a heavy chorus into a more relaxed break. It does this using a small window with barely any music at all. This makes it so that the algorithm is getting confused as to which parts of the song it should look for to determine the BPM. 
Finally, in the outro, the music slows down which is very visible in the loudness and timbre based novelty graphs. Now the algorithm lacks data points to determine the BPM again.

### The difference in tracks over two albums is clearly visible
```{R echo=FALSE}
all_tracks <-
  get_playlist_audio_features("bnfcollection", "2WAcLeFOdEps0dOIFpe0Dy") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

```{r echo=FALSE}
all_tracks_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      valence +
      tempo,
    data = all_tracks
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(all_tracks %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")
all_tracks_dist <- dist(all_tracks_juice, method = "euclidean")

```

```{r echo=FALSE}
ddata <- all_tracks_dist %>% 
  hclust(method = "complete")

colors = c("red", "blue")
clus4 = cutree(ddata, 4)
album <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)
plot(as.phylo(ddata), tip.color = colors[album],
     label.offset = 0.3, cex = 0.8)
```

***
In this dendrogram we can see how clusters of the newer album *One More Light* (shown in blue) are formed next to the older album *Hybrid Theory* (shown in red). 
The dendrogram is based on 7 track-level features:

* Danceability
* Energy
* Loudness
* Speechiness
* Acousticness
* Valence
* Tempo

We see that there are a few outliers, but it's easy to spot the heavy cluster forming. *Crawling* seems to be misgrouped with the rest of the songs of the *One More Light* album and on the other hand, *Invisible* seems to be grouped in the *Hybrid Theory* album. How *Invisible* gets into *Hybrid Theory* is something I do not completely understand. *Invisible* has a lot less energy and loudness compared to other songs, especially *One Step Closer* to which it is most similar according to the clustering algorithm. The valence, tempo and speechiness do sound rather similar to me, so this is my best guess as to why these two songs are clustered together. The exact same also goes for *Crawling* and *Sorry for Now*. These are clearly nu metal and pop songs respectively, but their valence, tempo and speechiness does sound similar to my ear.

Outside of the two large clusters, there are three outlier tracks that don't quite fit in. These are *Cure for the Itch*, *With You* and *One More Light*. The most striking to me is *One More Light*. The album is named after this song for a reason, it is definitely the defining track for the album. What makes it so that this song does not fit in with the rest, I do not know.

### Conclusion

All in all, we see that the older music of Linkin Park does indeed differ a lot from the newer music. Even though the newer albums and older albums are equally popular, the newer ones they have more well-defined chroma's, different musical structures and show a clearly downward spiral for their chords, which corresponds to the low point in the lead singer, Chester Bennington's life. These differences are so clearly visible that even a clustering algorithm could distinguish the old from the new albums with a decent accuracy.  

The Spotify API was very useful when researching this corpus as even with my very limited musical background, I was able to gain insights into many aspects of the corpus that were not clear beforehand.

***
<iframe src="https://open.spotify.com/embed/playlist/7MATpbz5p1afYISxOgY7ek?utm_source=generator" width="100%" height="99%" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

